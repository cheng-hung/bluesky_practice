{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f2791c9-c60e-4e37-a451-20a48c989e74",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyFAI'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyFAI\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyFAI\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcalibrant\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyFAI\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdetectors\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyFAI'"
     ]
    }
   ],
   "source": [
    "import pyFAI\n",
    "import pyFAI.calibrant\n",
    "import pyFAI.detectors\n",
    "import os, glob, re\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, HBox, VBox\n",
    "import ipywidgets as widgets\n",
    "from tifffile import imread, imshow, imsave\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.widgets import Slider, Button\n",
    "import yaml, tifffile\n",
    "%matplotlib widget\n",
    "\n",
    "def sum_everything(my_im1, my_im2, my_im3, use_mask_1, use_mask_2, use_mask_3, osetx = 27, osety = 27):\n",
    "    \"\"\" Assuming im2 offset by -osetx, -osety, and im3 offset by +osetx, +osety \"\"\"\n",
    "    \n",
    "    my_imsum = np.ones((my_im1.shape[0]+int(2*osetx), my_im2.shape[1]+int(2*osety),3))*np.nan\n",
    "\n",
    "    my_imsum[osetx:-osetx,osety:-osety,0] = my_im1\n",
    "    my_imsum[osetx:-osetx,osety:-osety,0][use_mask_1==1] = np.nan\n",
    "\n",
    "    my_imsum[:-int(2*osetx),:-int(2*osety):,1] = my_im2\n",
    "    my_imsum[:-int(2*osetx),:-int(2*osety):,1][use_mask_2==1] = np.nan\n",
    "\n",
    "    my_imsum[int(2*osetx):,int(2*osety):,2] = my_im3\n",
    "    my_imsum[int(2*osetx):,int(2*osety):,2][use_mask_3==1] = np.nan\n",
    "    return np.nanmean(my_imsum,axis=2)\n",
    "\n",
    "def image_sum():\n",
    "    data_dir = tiff_base_path + \"dark_sub/\"\n",
    "    meta_dir = tiff_base_path + \"meta/\"\n",
    "    Data = []\n",
    "    \n",
    "    os.chdir(data_dir)\n",
    "    Tiff, Meta = [], []\n",
    "    for file in os.listdir(data_dir):\n",
    "        if file.endswith(\".tiff\"):\n",
    "            Tiff.append(file)\n",
    "    #A.sort(key=lambda x: os.path.getmtime(x))\n",
    "    for file in os.listdir(meta_dir):\n",
    "        if file.endswith(\".yaml\"):\n",
    "            Meta.append(file)\n",
    "    Tiff.sort()\n",
    "    Meta.sort()\n",
    "    F_number = len(Tiff)\n",
    "    print(F_number)\n",
    "    print(len(Meta))\n",
    "\n",
    "    File_Name_Prefix = folder_name = os.path.basename(tiff_base_path.rstrip('/'))\n",
    "    sum_dir = os.path.join(data_dir, 'sum')\n",
    "    os.makedirs(sum_dir, exist_ok=True)  # Create 'sum' directory if it doesn't exist\n",
    "    \n",
    "    \n",
    "    for i in range(1, F_number, 3):  # Iterate with a step of 3\n",
    "        if (i+2) >= F_number:\n",
    "            break\n",
    "        im_spotA = imread(Tiff[i+0])\n",
    "        im_spotB = imread(Tiff[i+1])\n",
    "        im_spotC = imread(Tiff[i+2])\n",
    "    \n",
    "        with open(os.path.join(meta_dir, Meta[i]), 'r') as f:\n",
    "            data = yaml.unsafe_load(f)\n",
    "            T = data.get('more_info')['cryostat_A']\n",
    "    \n",
    "        full_imsum = sum_everything(im_spotC, im_spotB, im_spotA, use_mask_3, use_mask_2, use_mask_1, osety=27, osetx=27)\n",
    "        \n",
    "        # Save output file to the new 'sum' directory\n",
    "        tifffile.imsave(f\"{sum_dir}/{File_Name_Prefix}_Temperature_{T}_K_sum.tiff\", full_imsum)\n",
    "    print (i)\n",
    "    print (list(Tiff))\n",
    "\n",
    "\n",
    "def pct_integration():\n",
    "    i2d, q2d, chi2d = ai.integrate2d(img, binning, unit=UNIT,npt_azim=3600, polarization_factor=polarization, mask=mask0) # perform azimuthalintegration on one image to retain 2D information\n",
    "    intrinsic_mask_unrolled,_,_ = ai.integrate2d(mask0, binning, unit=UNIT,npt_azim=3600, polarization_factor=polarization, mask=mask0)  #trasnform mask0 (base mask) to the same coordinate space and cast it as type bool\n",
    "    #intrinsic_mask_unrolled = intrinsic_mask_unrolled.astype(bool) \n",
    "    outlier_mask_2d = np.zeros_like(i2d)     # Create an array to hold outlier mask\n",
    "\n",
    "    i2d, q2d, chi2d = ai.integrate2d(img, binning, unit=UNIT, npt_azim=3600, polarization_factor=polarization, mask=mask0)\n",
    "    mask1 = np.array(i2d<1)*1\n",
    "    \n",
    "    for ii, dd in enumerate(i2d.T):\n",
    "        low_limit, high_limit = np.percentile(dd, (ll,ul))\n",
    "        outlier_mask_2d[:,ii] = np.any([dd<low_limit, dd>high_limit, intrinsic_mask_unrolled[:,ii]], axis=0)\n",
    "    mask=outlier_mask_2d + mask1    \n",
    "    outlier_mask_2d_masked =  ma.masked_array(i2d, mask=outlier_mask_2d + mask1)     \n",
    "    data = np.column_stack((q2d, ma.mean(outlier_mask_2d_masked,axis=0)))\n",
    "    #plt.plot(q2d, ma.mean(outlier_mask_2d_masked,axis=0))\n",
    "    np.savetxt(directory + \"/dark_sub/sum/\" + str(a) + \"_L\" + str(ll)+ \"_U\" + str(ul) + \"_percentile_masked_\"+ str(UNIT) + \".dat\", data) # Uncomment when the data is ready to be saved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1640023e-9019-46c6-83ab-3cf4d59d8478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below stiches every three pilatus images in folders that end with 'PDF' in the tiff_base\n",
    "tiff_base_path = ('/nsls2/data/pdf/pdfhack/legacy/processed/xpdacq_data/user_data_Petkov_315831_79f731e2_2025-04-09-1101//tiff_base/')    \n",
    "use_mask_1= np.load(\"/nsls2/data/pdf/pdfhack/legacy/processed/xpdacq_data/user_data_Frandsen_315944_8496f7ec_2025-04-12-1911//config_base/masks/Mask_pos1_ext_BS.npy\") # This is mask we are applying befor mergin images\n",
    "use_mask_2 = np.load(\"/nsls2/data/pdf/pdfhack/legacy/processed/xpdacq_data/user_data_Frandsen_315944_8496f7ec_2025-04-12-1911//config_base/masks/Mask_pos2_ext_BS.npy\") # This is mask we are applying befor mergin images\n",
    "use_mask_3 = np.load(\"/nsls2/data/pdf/pdfhack/legacy/processed/xpdacq_data/user_data_Frandsen_315944_8496f7ec_2025-04-12-1911//config_base/masks/Mask_pos3_ext_BS.npy\") # This is mask we are applying befor mergin images\n",
    "\n",
    "# Get all folders ending with ending with '_PDF'. Alternativelly if you want to select a perticalur folder Type the folder name instead of \"*_PDF\"\n",
    "pdf_folders = glob.glob(tiff_base_path + \"*_PDF/\")\n",
    "for item in pdf_folders:\n",
    "    print(item)\n",
    "\n",
    "for directory in pdf_folders:\n",
    "    print(directory)\n",
    "    tiff_base_path = directory\n",
    "    image_sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac343356-f49e-4279-9da8-e1bc62067857",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai = pyFAI.load(\"/nsls2/data/pdf/pdfhack/legacy/processed//xpdacq_data/user_data_Frandsen_315944_8496f7ec_2025-04-12-1911/config_base/merged_PDF/merged.poni\" ) \n",
    "mask0 = np.load(\"/nsls2/data/pdf/pdfhack/legacy/processed//xpdacq_data/user_data_Frandsen_315944_8496f7ec_2025-04-12-1911/config_base/masks/stitched_2.npy\")\n",
    "binning = 5000\n",
    "polarization = 0.99\n",
    "UNIT = \"q_A^-1\"\n",
    "ll = 1 # lower percentile for the q dependent mask\n",
    "ul = 99  # Upper percentile for the q dependent mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ded440d-96be-4ac7-959d-d9c3fd2adf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrate applying a percentile + base mask and save 2 column data. Percentile masking remove outliers based on the intensity at each Q independently \n",
    "\n",
    "pdf_folders = glob.glob(tiff_base_path + \"*_PDF/\") # PDF folder selection\n",
    "\n",
    "for directory in pdf_folders:\n",
    "    print(directory)\n",
    "    for file in os.listdir(directory + \"/dark_sub/sum/\"):\n",
    "        #print(directory)\n",
    "        if file.endswith(\".tiff\"):\n",
    "            img = imread(directory + \"/dark_sub/sum/\" + file)\n",
    "            print(file)\n",
    "            a,b = os.path.splitext(file)\n",
    "            pct_integration()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c29f5d-3e58-4ec6-8879-037393a5b6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrate only applying a base_mask and save 2 column data) \n",
    "pdf_folders = glob.glob(tiff_base_path + \"*_PDF/\")\n",
    "#for item in pdf_folders:\n",
    "#    print(item)\n",
    "\n",
    "for directory in pdf_folders:\n",
    "    print(directory)\n",
    "    for file in os.listdir(directory + \"/dark_sub/sum/\"):\n",
    "        #print(directory)\n",
    "        if file.endswith(\".tiff\"):\n",
    "            img = imread(directory + \"/dark_sub/sum/\" + file)\n",
    "            a,b = os.path.splitext(file)\n",
    "            x,y = ai.integrate1d(img, binning, mask=mask0, unit=UNIT, polarization_factor=polarization) \n",
    "            data = np.column_stack((x, y))\n",
    "            np.savetxt(directory + \"/dark_sub/sum/\" + str(a) + \".dat\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cf7142-057b-466a-b5df-de344d791cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
